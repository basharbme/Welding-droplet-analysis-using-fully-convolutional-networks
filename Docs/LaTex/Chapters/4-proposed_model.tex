\chapter{Proposed approach using Fully Convolutional Networks}\label{chap:proposed_model}

In this chapter the proposed models are described. These consist in FCN based deep learning architectures which are compared in the same datasets to ensure validated results and also to choose the best performing model for further analysis. The architectures are described using baseline parameters that will then be optimized using a grid search. In figure \ref{fig:flowchart} a flowchart of the proposed framework is shown.

\section{Segmentation architectures}
The architectures used are FCN based, so they share they building blocks shown in figure \ref{fig:fcn}. There is a contracting path of successive convolution and pooling layers and then an expanding path that mirrors the shape of the contracting one by applying transposed convolutions (upsampling) instead of pooling. Also, in the contracting path the number of feature maps increases while in the expanding path it decreases until reaching the output's number of channels. The segmentation architectures used are:

\begin{itemize}
    \item \textbf{DeconvNet:} This network is an FCN which uses a VGGNet \cite{vggnet} as a backbone for the contracting path. The expanding path mirrors the VGGNet architecture. Since it is based in a network that has already proven to have good results with image data it is appropriate to extend its application \cite{vggnet, Noh}. In figure \ref{fig:deconv} the contracting path is shown.

    \item \textbf{U-Net:} The U-Net is an FCN that was first implemented in the biomedical field for microscopy images. The architecture is shown in figure \ref{fig:unet} and makes use of skip layers which are taken from the contracting path and then concatenated in the expanding path layers. This allows the network to localize specific data by reducing dimensionality and also have the context of the general image through the skip layers \cite{Ronneberger}.
    


    \item \textbf{MultiResUnet:} This is an improvement of the U-Net, than can process subjects which have large differences in scale within an image. This is done with several convolutions with different kernels so that the features are learned at different resolutions, this is borrowed from Inception architectures such as GoogLeNet \cite{inception}. The structure is the same as in figure \ref{fig:unet} but the convolution blocks are changed with residual blocks that apply different convolutions which are then summed. Also, skip connections have a residual residual path in between. Figure \ref{fig:multires} shows the residual block used and figure \ref{fig:respath} depicts the residual connections used in the skip layers.
\end{itemize}

\begin{figure}
    \centering
     \resizebox{\linewidth}{!}{
    \includegraphics{Images/Background/framework_flow_chart.pdf}
    }
    \caption[Proposed framework flowchart]{Proposed framework flowchart.}
    \label{fig:flowchart}
\end{figure}

\begin{figure}
    \centering
    \resizebox{\linewidth}{!}{
    \input{Graphs/deconvnet}
    }
    \caption[Illustration of a DeconvNet contracting path]{Illustration of a DeconvNet contracting path. A VGGNet architecture is used and then mirrored in the expanding path. At the top of each block the kernel shape is shown, below are depicted the number of feature maps per convolution. Finally, $I$ is the input size which is halved after each pooling layer. Source: Adapted from \url{https://github.com/HarisIqbal88/PlotNeuralNet}.}
    \label{fig:deconv}
\end{figure}

\begin{figure}
    \centering
    \resizebox{\linewidth}{!}{
    \input{Graphs/unet}
    }
    \caption[Illustration of a U-Net architecture]{Illustration of a U-Net architecture. The architecture is divided in a contracting path and an expanding path. The contracting path has conv (yellow)/conv/pool (red) blocks. The expanding path has transposed-conv (blue)/conv/conv blocks. Dimensions in the expanding path mirror the contracting path. Each convolution before pooling is used as a skip layer and concatenated with the corresponding shape in the expanding path. The final layer reduces the feature maps to one and applies a softmax function for pixel-wise classification. Convolution kernels are $3\times 3$ while pooling kernels are $2\times 2$ so the size is halved at each block. Source: Adapted from \url{https://github.com/HarisIqbal88/PlotNeuralNet}.}
    \label{fig:unet}
\end{figure}

\begin{figure}
    \centering
    \resizebox{\linewidth}{!}{
    \input{Graphs/multires}
    }
    \caption[Illustration of a Multi Resolution block]{Illustration of a Multi Resolution block. The block consists of successive convolutions which are then stacked via skip layers and then summed using a residual connection. The second and third convolutional blocks are stacked convolutions of $3\times3$ kernels which are factorized operations of $5\times 5$ and $7 \times7$ convolutions respectively \cite{conv-factor}. This approach is more computationally efficient than using parallel higher resolution kernels. Source: Adapted from \url{https://github.com/HarisIqbal88/PlotNeuralNet}.}
    \label{fig:multires}
\end{figure}

\begin{figure}
    \centering
    \resizebox{0.5\linewidth}{!}{
    \input{Graphs/respath}
    }
    \caption[Illustration of a residual path]{Illustration of a residual path. This type of block is used in series in the MultiResUnet in between skip layers, so the skipped features are processed before being concatenated to the expanding path. Source: Adapted from \url{https://github.com/HarisIqbal88/PlotNeuralNet}.}
    \label{fig:respath}
\end{figure}

\clearpage
\section{Segmentation loss function}

As stated earlier, to train a supervised neural network it is necessary to have some measure of error so that it can be minimized with respect to the weights. This measure is the loss function which depends on the task. In the case of semantic segmentation, it is necessary to use a loss function that can capture pixel-wise comparisons. Specifically, for supervised segmentation, the input is an image, the output is a 2D mapping of each pixel of the image to a certain class (e.g. pixel$ = 0$ if background and pixel$ = 1$ if foreground) and the output is compared through the loss function with a previously labeled image with the same kind of segmentation mapping corresponding to the input image. A widely used loss metric for supervised semantic segmentation is the intersection over union metric, also known as Jaccard index. This metric is given by
\begin{align*}
    J(A, B) = \frac{|A\cap B|}{|A\cup B|}
\end{align*}
where $|\cdot|$ is the cardinality of the set. Hence, if the overlap is perfect $|A\cap B|=|A\cup B|\xrightarrow[]{} J=1$. Conversely, if there is no overlap $|A\cap B|=0\xrightarrow{} J=0$. In a segmentation mapping, $|A\cap B|$ can be computed as the element-wise multiplication of $A$ and $B$, and then sum the result. Furthermore, $|\cdot|$ is computed as the sum of the matrix' elements. The score is computed over all classes and then averaged.
    
In order to minimize a loss function using the Jaccard index, the Jaccard distance is defined and is given by
\begin{align*}
    d_j(A,B)=1-J(A,B)
\end{align*}

\section{Validation}
The proposed architectures have to be validated to ensure that the best results are obtained. Then, every model is subject to a grid search. The parameters used for grid search are shown in table \ref{table:grid_search}. Also, each model (i.e. each point in the grid) is run using $k$-fold cross validation with $k=4$. That is, each model is run four times with a different and disjoint $25\%$ of validation data each time. The average loss in the validation set is used to compare the models' performances and choose the best one. The parameters are considered for each proposed architecture. Also, separate models are trained for globular and spray datasets.

\begin{table}
\centering
\caption{Hyperparameters used for grid search. Every parameter is used for each proposed architecture (DeconvNet, U-Net and MultiResUnet) and each dataset (globular and spray) is trained separately.}
\label{table:grid_search}
\begin{tabular}{|c|c|c|c|c|}
\cline{1-2} \cline{4-5}
Batch size                                              & 8, 16, 32       &  & Epochs        & \begin{tabular}[c]{@{}c@{}}Max: 200\\ Patience: 20\end{tabular} \\ \cline{1-2} \cline{4-5} 
Filters                                                 & 8, 16, 32       &  & Loss function & \begin{tabular}[c]{@{}c@{}}Jaccard\\ distance\end{tabular}      \\ \cline{1-2} \cline{4-5} 
\begin{tabular}[c]{@{}c@{}}Learning\\ rate\end{tabular} & .01, .005, .001 &  & Optimizer     & Adam                                                            \\ \cline{1-2} \cline{4-5} 
\end{tabular}
\end{table}
