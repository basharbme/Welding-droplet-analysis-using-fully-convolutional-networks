\chapter{Concluding remarks and future work}\label{chap:conclusions}
\section{Conclusions}
In this work the aim is to be able to implement a novel approach to GMAW video analysis using deep learning to gain further understanding of the process.

First, a small dataset was manually labeled in order to train in a supervised fashion. Additionally, manual labels were augmented using image augmentation. Then, despite having a large, unlabeled dataset, it is possible to generate a working dataset with relative ease and, more importantly, results can be improved simply by generating more labels.

The proposed deep learning architectures based on Fully Convolutional Networks prove to be good candidates to approach the segmentation problem after validating results using grid search and comparing the DeconvNet, U-Net and MultiResUnet architectures. Specifically the U-Net architecture is able to reach a small loss in training and generates accurate mappings for most of the images while not being an excessively complex model. This approach is able to generate segmentation mappings of thousands of images in seconds/minutes as opposed to previous work which was more centered in analyzing a handful of images.

Nevertheless, the network has some drawbacks when predicting segmentation maps, particularly over-segmentation due to the brightness and reflection of the welding pool. This can be solved by adding more data to the model, since the labels were made  with a diversity in geometry as a priority and not the mentioned problems, which is why the shape of the actual droplets is mostly correctly segmented.

Later, the calculation of relevant parameters that characterize the process is carried out, namely for droplet location (centroid), velocity, acceleration, perimeter, area, detachment frequency, volume and surface tension. The perimeter, area and volume are calculated throughout the whole video and the rest of the parameters are obtained in specific time windows during the free flight movement of droplets since these parameters only make sense when analyzing a specific droplet, as opposed to the constant stream of droplets. Specific droplets can be tracked simply by using a continuity criterion for their location.

The obtained parameters are compared with literature values and most of them lie within expected ranges, although there is discrepancy, mainly due to different experimental setups and focus of the analysis of different papers. Nonetheless, these parameters can help gain a better understanding of the process by measuring droplet detachment rate which can be further used for deposition rate using density and volume calculations. Also, kinematic properties are relevant since acceleration and mass (given volume and density) can be related to the forces affecting the droplet. Furthermore, velocity can be related to kinematic energy of the droplet. Nevertheless, the parameters calculated here are rather exploratory, and more information could be gained depending on the context and necessity of the experiment.

In conclusion, the U-Net is able to successfully generate segmentation mappings of globular and spray GMAW metal transfer. Then, several geometric and physical parameters are obtained, mostly in agreement with the literature. Then, these can be used to better understand the process which in turn can help to analyze and optimize the process. The main drawbacks can be solved by gathering more data and increasing its resolution. Consequently, this opens many possibilities to apply deep learning in the welding field for many applications given that deep learning techniques have not been widely adopted in the field yet.


\section{Further work}

A number of possibilities arise given that the proposed model is successful. First, more experiments can be carried out to have a better comparison ground against the available literature. A common approach is to get results for different current intensities and measuring more parameters (e.g. temperature). Moreover, a use of gear with more spatial and time resolution would be helpful when computing some parameters that come from higher frequencies. Also, as with all data driven models, results can improve greatly if more data is available. Specifically, investing efforts in generating proper labels and augmenting them can help overcome the drawbacks mentioned before.

The architectures used are mainly for image data, but in this case, since videos are used, it could be beneficial to couple the used models with recurrent networks which make use of the temporal dependence of the data. Also, there are segmentation models that are used in videos (as opposed to separate images) such as Fast-RCNN and Mask-RCNN which could also be used. Another improvement would be using transfer learning, to take advantage of previously trained strong models. Additionally, instance segmentation would be a natural next step to improve semantic segmentation

Finally, since this work is mainly an offline tool, that is, it is intended to analyze the process after it has been carried out, it would be interesting to apply the same procedure in an online fashion, retrieving data in real time which would be helpful in the welding in-situ operation.
