\chapter{Methodology}\label{chap:methodology}

This work explores the use of supervised deep learning segmentation models to process GMAW high speed videos for further postprocessing. The process to achieve this is as follows:

\begin{enumerate}
    \item \textbf{Literature review:} The first step consists in broadly studying the GMAW welding process and why it would be important to optimize and understand it better. Furthermore, the specific approach of image segmentation is studied within the field, to know what has been done until now.\\ 
    
    In parallel, a study of the deep learning segmentation models and applications is carried out to know the tools available to solve the task and which kinds of problems have been tackled so far.\\
    
    \item \textbf{Gathering and preprocessing the data:}
    The dataset used was kindly provided by the Canadian Centre for Welding and Joining (CCWJ). These are high speed videos of GMAW processes for globular and spray transfer modes. The videos are \texttt{.cine} files which are read in \texttt{python} with the use of the \texttt{pycine} library. In this way, each video is stored as a 4D array (time, width, height, channels) into a \texttt{.npz} file.\\
    
    Additionally, since the proposed model is supervised, a small sample of images is taken to be labeled using LabelBox. The samples are carefully selected so that the whole process is depicted. Also, each transfer mode has its own set of sampled data.\\
    
    Finally, the dataset is artificially augmented because the amount labeled images is rather small. Multiple transformations are performed such that each image yields five augmented images.\\
    
    \item \textbf{Develop semantic segmentation models:}
    A handful of models are used to be compared, these are the U-Net, DeconvUnet and MultiResUnet, they are built in \texttt{tensorflow} 2.3.1. The models are trained with image files from the sampled ones that have labels, then the rest of the images without labels are tested. Since there are two different transfer modes considered, globular and spray, they are trained separately, so for each network there are two trained models. Moreover, several validation methods are used to ensure the best results such as $k$-fold cross validation and grid searching, all of which are described in chapter \ref{chap:background}.\\
    
    \item \textbf{Postprocess segmentation masks:}
    The outputs of the segmentation network are then processed using \texttt{opencv} and \texttt{scipy} to calculate several relevant characteristics such as position, velocity, acceleration, area, volume and surface tension among others.\\
    
    \item \textbf{Analysis and conclusion:}
    The proposed models are compared to discuss about which one would be better for the task. Additionally, the postprocessed features are discussed in terms of their usefulness when optimizing or designing a GMAW process. Finally, future prospects of deep learning techniques in the welding industry are presented.
    
\end{enumerate}

\section{Resources available for this Thesis}
The computational requirements for this thesis were met by a desktop computer provided by the Smart Reliability and Maintenance Integration (SRMI) Laboratory of the University of Chile with the following specifications:
\begin{itemize}
    \item Ubuntu 16.04.06 LTS.
    \item Intel Core i5-7600K CPU @ 3.80GHz x 4. 
    \item 32GB RAM.
    \item NVIDIA TITAN Xp/PCIe/SSE2.
\end{itemize}

Additionally, the software and libraries needed include:
\begin{itemize}
    \item Phantom Camera Control software to view \texttt{.cine} files and inspect metadata.
     \item LabelBox tools for manual segmentation of images.
    \item \texttt{Python} 3.8 as programming language.
    \item \texttt{Pycine} library to read \texttt{.cine} files in \texttt{python}\footnote{\url{https://github.com/OTTOMATIC-IO/pycine}}.
    \item \texttt{Imgaug} for augmenting images.
    \item \texttt{TensorFlow} 2.3.1 as a deep learning framework.
    \item \texttt{Numpy}, \texttt{pillow}, \texttt{scikit-learn}, \texttt{opencv}, \texttt{scipy} for preprocessing and post-processing of data.
    \item \texttt{Matplotlib} and \texttt{seaborn} for data visualization.
    \item Dependencies required for the above to work properly.
\end{itemize}

Regarding the dataset, it was provided by the Canadian Centre for Welding and Joining (CCWJ) at the University of Alberta, this collaboration was carried out through the Emerging Leaders in the Americas Program (ELAP) which awarded the author a scholarship to undergo an investigation internship at the University of Alberta for a period of six months.

Finally, version control of the project is carried out using Git. All of the code, results and related documents can be found in GitHub\footnote{\url{https://github.com/igonzalezperez/Welding-droplet-analysis-using-fully-convolutional-networks}.}.